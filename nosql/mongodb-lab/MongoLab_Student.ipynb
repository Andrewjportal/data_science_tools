{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMongoLab (Student)\n",
    "\n",
    "We will use the `author` and `catalog` datasets in the `data` directory, and practice some queries on them using `pymongo`. To get ourselves started:\n",
    "\n",
    "1. Make sure `mongod` is running (it should be from previous exercise)\n",
    "2. Make sure the books dataset has been entered (from 01_mongo_shell.md)\n",
    "3. Make sure the catalog dataset has been entered (from 01_mongo_shell.md)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a client that uses the default port on localhost.\n",
    "# If connecting to AWS, you need a connection string.\n",
    "# Can do the same thing with MongoClient(\"mongodb://localhost:27017\")\n",
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it look similar to shell mongo\n",
    "db = client.books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should have the 'author' collection we used before and the 'catalog' collection.\n",
    "# If not, you haven't connected to the right database, or haven't uploaded the data!\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: find\n",
    "\n",
    "The `find` command is similar to the shell, but it returns a _cursor_. This allows you to scroll through a lot of data at once, without loading it into memory at once. The basic format is\n",
    "```python\n",
    "cursor = db.collection.find( where_dictionary, what_fields_dictionary} )\n",
    "```\n",
    "\n",
    "Here \n",
    "* `where_dictionary` tells us what properties a document needs to be returned. Similar to the WHERE clause in SQL\n",
    "* `what_fields_dictionary` tells us which fields we want returned. With the exception of `_id`, we either start with nothing and include fields (use `fieldname: True`), or start with everything and exclude fields (use `fieldname: False`). Note `1` and `0` are often used instead of `True` and `False`\n",
    "\n",
    "To get results our of a cursor:\n",
    "\n",
    "1. Can convert cursor to list: `list(cursor)`\n",
    "  * Make sure the data is \"small\" before doing this. You are asking for _all_ the results at once, which could be large.\n",
    "  * Defeats the point of a cursor\n",
    "2. Iterate through the cursor:\n",
    "```python\n",
    "for result in cursor:\n",
    "    # .... do something with the results one at a time\n",
    "```"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the names of each of the authors\n",
    "cursor = db.author.find({}, {'_id':0, 'name': 1})\n",
    "list(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select from subfields, using the same sort of `field.subfield` syntax that we used in the shell"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the book titles with the author\n",
    "cursor = db.author.find({}, {'_id':0, 'name': 1, 'books.title':1})\n",
    "\n",
    "list(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You do: Exercise 1 (3 minutes)\n",
    "\n",
    "List each of the author names, with the book titles, the total number of sales for that book, and summary.\n",
    "e.g. a line of output might be\n",
    "```python\n",
    "[....., \n",
    " {'books': [{'title': 'Tender Wings of Desire', 'sold': 10, 'description': .......}], 'name': 'Harland Sanders'},\n",
    " ....]\n",
    "```\n",
    "\n",
    "\n",
    "HINT: You might want to run \n",
    "```python\n",
    "list(db.author.find().limit(1))\n",
    "```\n",
    "first, so that you can see the typical names of the fields."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You do: Exercise 2 (5 mins)\n",
    "\n",
    "The results above are a little ugly. Write a loop that outputs the following statement for each author:\n",
    "```\n",
    "<Author name> has sold a total of <sum of all book sales> books\n",
    "```\n",
    "\n",
    "You can either use the query above, or (if adventurous) try using an `aggregation`."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert\n",
    "\n",
    "If collecting results from webscraping or an API, you might want to insert new books. Let's insert  Chuck Palahniuk into the database.\n",
    "\n",
    "Note that we have __not__ included his nationality or wikipedia page. This is emphasizing that unlike SQL tables, it is up to us which fields we put in the database. We _should_ include this information (it is relevant here) but the NoSQL design puts it on us to remember to do it -- we are not going to get a warning that fields are \"missing\"! \n",
    "\n",
    "Note that the entries in `books` don't have a number sold either!\n",
    "\n",
    "We also would not get an error if we renamed `books` to `book`, or `published_books`. It is important to be disciplined when entering data into a NoSQL database"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document = {\n",
    "    'name': ' Chuck Palahniuk',\n",
    "    'books': [{\n",
    "        'title': 'Fight club',\n",
    "        'year': 1999,\n",
    "        'description': 'A man and his imaginary friend make a fight club ..... with soap'\n",
    "    },\n",
    "    {\n",
    "        'title': 'Lullaby',\n",
    "        'year': 2002,\n",
    "        'pages': 272,\n",
    "        'publisher': 'Doubleday',\n",
    "        'description': 'A lullaby that kills people more effectively than the telephone call in \"The Ring\"'\n",
    "    }]\n",
    "}\n",
    "\n",
    "## You do: insert the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also `insert_many` which you could use to insert a list of new documents.\n",
    "\n",
    "```python\n",
    "db.author.insert_many( [new_doc1, new_doc2, ...., new_docN] )\n",
    "```"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: You do (8 mins)\n",
    "\n",
    "The code below loads a set of famous lines from the data directory. Add a new collection, `quotes`, to the books database that has documents in the following form:\n",
    "```python\n",
    "{'name': <quote author>, 'title': <title of book>, 'quote': <quotation>}\n",
    "```"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview the data\n",
    "quotes = [line.split('|') for line in open('data/famous_lines.txt', 'r').readlines()]\n",
    "quotes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: load into the database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: you do (2 mins)\n",
    "\n",
    "Find the quotation from 1984"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: we do (2 mins)\n",
    "\n",
    "Find the number of quotes we loaded. There are lots of ways of doing this, and some are better than others, so we'll do this as a group."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete and dropping \n",
    "\n",
    "Let's restore the db to how we started it. We are going to\n",
    "- drop the `quotes` collection\n",
    "- delete the Chuck Palahniuk document\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_collection('quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.author.delete_one({'name': 'Chuck Palahniuk'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "Aggregations allow us to chain a set of operations together. An aggregation takes a list of operations that are executed in order. It is similar to the _pipeline_ that we used in sklearn. Each operation is a dictionary of the form\n",
    "```python\n",
    "{ operation_name : operation_arguments}\n",
    "```\n",
    "\n",
    "Here are the common operations:\n",
    "\n",
    "| Operation name | Description | Arguments |\n",
    "| --- | --- | --- |\n",
    "| `'$match'` | Acts like a where clause, similar to the first argument in `find`| A dictionary | \n",
    "| `'$group'` | Aggregates documents together | A dictionary. Must have an `_id` field to group objects together |\n",
    "| `'$unwind'` | \"Unwinds\" a field that has an entry. See description below | A string (name of field to unwind) |\n",
    "| `'$project'` | Includes or excludes fields. Similar to the second argument of `find`. Can also be used to rename fields | A dictionary |\n",
    "| `'$sample'` | Samples `n` items randomly | A dictionary of form `{'size': n}` | \n",
    "| `'$limit'` | Limits the collection to the first `n` items | A positive integer `n` | \n",
    "| `'$sort'` | Sorts the collection based on field names passed | `{'fieldname2': 1, 'fieldname2':1, .... }` |\n",
    "\n",
    "There are other operations like bucketing (binning data for histograms, skip and offset (for scrolling through data). A complete list can be found here: https://docs.mongodb.com/manual/reference/operator/aggregation/sort/\n",
    "\n",
    "#### Unwind\n",
    "\n",
    "Unwind is a little hard to describe, but not difficult to understand. If a field has an array, `$unwind` duplicates the record for each entry in the array. For example, let's say we have the document\n",
    "```python\n",
    "{\n",
    "    'name': 'Vader',\n",
    "    'campaigns': ['Mufasar', 'Death Star 1', 'Death Star 2'],\n",
    "    'powers': ['force choke', 'telekinesis'],\n",
    "    'allegience': 'dark side'\n",
    "}\n",
    "```\n",
    "\n",
    "If we `$unwind` on `campaigns`, we get 3 documents, one for each campaign:\n",
    "```python\n",
    "## result of {'$unwind': '$campaigns'} on above\n",
    "[{\n",
    "    'name': 'Vader',\n",
    "    'campaigns': 'Mufasar',\n",
    "    'powers': ['force choke', 'telekinesis'],\n",
    "    'allegience': 'dark side'\n",
    "},\n",
    "{\n",
    "    'name': 'Vader',\n",
    "    'campaigns': 'Death Star 1',\n",
    "    'powers': ['force choke', 'telekinesis'],\n",
    "    'allegience': 'dark side'\n",
    "},\n",
    "{\n",
    "    'name': 'Vader',\n",
    "    'campaigns': 'Death Star 2',\n",
    "    'powers': ['force choke', 'telekinesis'],\n",
    "    'allegience': 'dark side'\n",
    "}]\n",
    "```"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Check for understanding (4 mins)\n",
    "\n",
    "\n",
    "Here is a query to try and find books that sold more than 70,000,000 copies. We use the \n",
    "`'books.sold' : {'$gt': 700000}` to select books that sold more than 70000000 copies, yet results were incorrect\n",
    "\n",
    "**Why doesn't this query work?**\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(db.author.find({'books.sold': {'$gt': 70000000}}, {'books.title': 1, 'name': 1, 'books.sold': 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anwer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer is ......."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: We do (8 mins)\n",
    "\n",
    "Write an aggregation that selects only the best sellers (more than 70 million copies)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common trick -- counting records per group\n",
    "\n",
    "In the Chicago restaurant dataset, we had restaurants with different \"price\" points. What if we wanted to count how many restaurants were at each price point?\n",
    "\n",
    "Mongo uses aggregation to solve this. The idea is when grouping, we assign each record the number `1`, then sum them. Let's see an example."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {'$group': {'_id': '$price', 'num_restaurants': {'$sum': 1}}},   # group by price, add 1 for every record and store i num_restaurants\n",
    "    {'$project': {'_id': 0, 'price': '$_id', 'num_restaurants': 1}}, # rename _id to price\n",
    "    {'$sort': {'price': 1}}                                         # sort by price rating, ascending\n",
    "]\n",
    "\n",
    "list(client.outings.restaurant.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be practice with aggregations in tomorrow's pair!"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
